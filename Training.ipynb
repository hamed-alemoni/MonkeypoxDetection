{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.layers import AveragePooling2D, Conv2D, MaxPool2D, ZeroPadding2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Give 'dataset_directory' path of test folder(you can change the other variables according to your need)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "dataset_directory = '/content/drive/MyDrive/MSID/test'\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "TEST_BATCH_SIZE = 22\n",
    "test_data = test_generator.flow_from_directory(dataset_directory, target_size=IMAGE_SHAPE, batch_size=TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Give 'dataset_directory' path of train folder(you can change the other variables according to your need)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "dataset_directory = '/content/drive/MyDrive/MSID/train'\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "TRAIN_BATCH_SIZE = 20\n",
    "train_data = train_generator.flow_from_directory(dataset_directory, target_size=IMAGE_SHAPE, batch_size=TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I designed this model it is not as good as DensNet an I hope you can improve it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(224, 224, 3)))\n",
    "model.add(Conv2D(32, 3, activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=2, strides=2))\n",
    "model.add(Dropout(0.3)) # to prevent overfitting\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, 3, activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=2, strides=2))\n",
    "model.add(Dropout(0.3)) # to prevent overfitting\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4)) # to prevent overfitting\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet201(weights=None, classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when see all batches go to next epoch(steps_per_epoch & validation_steps)\n",
    "history = model.fit(train_data, steps_per_epoch=length_of_train_data, validation_data=test_data, validation_steps=length_of_test_data, epochs=25)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
